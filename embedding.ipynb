{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>hydrophobicity_polar_first</th>\n",
       "      <th>hydrophobicity_polar_20%</th>\n",
       "      <th>hydrophobicity_polar_40%</th>\n",
       "      <th>hydrophobicity_polar_60%</th>\n",
       "      <th>hydrophobicity_polar_80%</th>\n",
       "      <th>hydrophobicity_polar_100%</th>\n",
       "      <th>hydrophobicity_neutral_first</th>\n",
       "      <th>...</th>\n",
       "      <th>solvent_accessibility_intermediate_40%</th>\n",
       "      <th>solvent_accessibility_intermediate_60%</th>\n",
       "      <th>solvent_accessibility_intermediate_80%</th>\n",
       "      <th>solvent_accessibility_intermediate_100%</th>\n",
       "      <th>solvent_accessibility_exposed_first</th>\n",
       "      <th>solvent_accessibility_exposed_20%</th>\n",
       "      <th>solvent_accessibility_exposed_40%</th>\n",
       "      <th>solvent_accessibility_exposed_60%</th>\n",
       "      <th>solvent_accessibility_exposed_80%</th>\n",
       "      <th>solvent_accessibility_exposed_100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WP_395757889.1</td>\n",
       "      <td>AMP</td>\n",
       "      <td>MPYDSVYLEKRPPGALRTVWRKFYGDTTAMIGLYGCAGLLLLCVFG...</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>18.918919</td>\n",
       "      <td>30.405405</td>\n",
       "      <td>63.175676</td>\n",
       "      <td>80.405405</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>...</td>\n",
       "      <td>37.162162</td>\n",
       "      <td>54.054054</td>\n",
       "      <td>73.648649</td>\n",
       "      <td>93.243243</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>18.918919</td>\n",
       "      <td>30.405405</td>\n",
       "      <td>63.175676</td>\n",
       "      <td>80.405405</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WP_395755974.1</td>\n",
       "      <td>AMP</td>\n",
       "      <td>MKILIVEDDTLIQQGLAQAMARENYAYDCADSAVGASALLQSSHYS...</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>25.454545</td>\n",
       "      <td>44.090909</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>83.181818</td>\n",
       "      <td>99.090909</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>37.727273</td>\n",
       "      <td>64.545455</td>\n",
       "      <td>84.545455</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>25.454545</td>\n",
       "      <td>44.090909</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>83.181818</td>\n",
       "      <td>99.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WP_395732316.1</td>\n",
       "      <td>AMP</td>\n",
       "      <td>MDFSRKPTQDPEAWLDFAPEFSQSMARQVRGWIQRWEPDLAESIKW...</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>18.226601</td>\n",
       "      <td>41.871921</td>\n",
       "      <td>60.591133</td>\n",
       "      <td>86.206897</td>\n",
       "      <td>99.507389</td>\n",
       "      <td>1.970443</td>\n",
       "      <td>...</td>\n",
       "      <td>39.901478</td>\n",
       "      <td>63.054187</td>\n",
       "      <td>78.325123</td>\n",
       "      <td>95.073892</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>18.226601</td>\n",
       "      <td>41.871921</td>\n",
       "      <td>60.591133</td>\n",
       "      <td>86.206897</td>\n",
       "      <td>99.507389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WP_395723680.1</td>\n",
       "      <td>AMP</td>\n",
       "      <td>MDCSRTPTRDPETWLDLAPEFSQAMARQVRAWIQRWEPDLTESIKW...</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>19.211823</td>\n",
       "      <td>47.783251</td>\n",
       "      <td>65.517241</td>\n",
       "      <td>86.699507</td>\n",
       "      <td>99.507389</td>\n",
       "      <td>1.970443</td>\n",
       "      <td>...</td>\n",
       "      <td>32.512315</td>\n",
       "      <td>49.753695</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>92.118227</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>19.211823</td>\n",
       "      <td>47.783251</td>\n",
       "      <td>65.517241</td>\n",
       "      <td>86.699507</td>\n",
       "      <td>99.507389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WP_395695240.1</td>\n",
       "      <td>AMP</td>\n",
       "      <td>MADRDTAGVTFETTVSSFGNNTGIEVPEEVIERLGRGKRPPVLVTV...</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>20.512821</td>\n",
       "      <td>45.512821</td>\n",
       "      <td>71.794872</td>\n",
       "      <td>89.102564</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.282051</td>\n",
       "      <td>...</td>\n",
       "      <td>34.615385</td>\n",
       "      <td>53.205128</td>\n",
       "      <td>76.282051</td>\n",
       "      <td>88.461538</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>20.512821</td>\n",
       "      <td>45.512821</td>\n",
       "      <td>71.794872</td>\n",
       "      <td>89.102564</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Label                                           Sequence  \\\n",
       "0  WP_395757889.1   AMP  MPYDSVYLEKRPPGALRTVWRKFYGDTTAMIGLYGCAGLLLLCVFG...   \n",
       "1  WP_395755974.1   AMP  MKILIVEDDTLIQQGLAQAMARENYAYDCADSAVGASALLQSSHYS...   \n",
       "2  WP_395732316.1   AMP  MDFSRKPTQDPEAWLDFAPEFSQSMARQVRGWIQRWEPDLAESIKW...   \n",
       "3  WP_395723680.1   AMP  MDCSRTPTRDPETWLDLAPEFSQAMARQVRAWIQRWEPDLTESIKW...   \n",
       "4  WP_395695240.1   AMP  MADRDTAGVTFETTVSSFGNNTGIEVPEEVIERLGRGKRPPVLVTV...   \n",
       "\n",
       "   hydrophobicity_polar_first  hydrophobicity_polar_20%  \\\n",
       "0                    1.351351                 18.918919   \n",
       "1                    0.909091                 25.454545   \n",
       "2                    0.985222                 18.226601   \n",
       "3                    0.985222                 19.211823   \n",
       "4                    1.923077                 20.512821   \n",
       "\n",
       "   hydrophobicity_polar_40%  hydrophobicity_polar_60%  \\\n",
       "0                 30.405405                 63.175676   \n",
       "1                 44.090909                 63.636364   \n",
       "2                 41.871921                 60.591133   \n",
       "3                 47.783251                 65.517241   \n",
       "4                 45.512821                 71.794872   \n",
       "\n",
       "   hydrophobicity_polar_80%  hydrophobicity_polar_100%  \\\n",
       "0                 80.405405                 100.000000   \n",
       "1                 83.181818                  99.090909   \n",
       "2                 86.206897                  99.507389   \n",
       "3                 86.699507                  99.507389   \n",
       "4                 89.102564                 100.000000   \n",
       "\n",
       "   hydrophobicity_neutral_first  ...  solvent_accessibility_intermediate_40%  \\\n",
       "0                      0.675676  ...                               37.162162   \n",
       "1                      4.545455  ...                               37.727273   \n",
       "2                      1.970443  ...                               39.901478   \n",
       "3                      1.970443  ...                               32.512315   \n",
       "4                      1.282051  ...                               34.615385   \n",
       "\n",
       "   solvent_accessibility_intermediate_60%  \\\n",
       "0                               54.054054   \n",
       "1                               64.545455   \n",
       "2                               63.054187   \n",
       "3                               49.753695   \n",
       "4                               53.205128   \n",
       "\n",
       "   solvent_accessibility_intermediate_80%  \\\n",
       "0                               73.648649   \n",
       "1                               84.545455   \n",
       "2                               78.325123   \n",
       "3                               68.965517   \n",
       "4                               76.282051   \n",
       "\n",
       "   solvent_accessibility_intermediate_100%  \\\n",
       "0                                93.243243   \n",
       "1                               100.000000   \n",
       "2                                95.073892   \n",
       "3                                92.118227   \n",
       "4                                88.461538   \n",
       "\n",
       "   solvent_accessibility_exposed_first  solvent_accessibility_exposed_20%  \\\n",
       "0                             1.351351                          18.918919   \n",
       "1                             0.909091                          25.454545   \n",
       "2                             0.985222                          18.226601   \n",
       "3                             0.985222                          19.211823   \n",
       "4                             1.923077                          20.512821   \n",
       "\n",
       "   solvent_accessibility_exposed_40%  solvent_accessibility_exposed_60%  \\\n",
       "0                          30.405405                          63.175676   \n",
       "1                          44.090909                          63.636364   \n",
       "2                          41.871921                          60.591133   \n",
       "3                          47.783251                          65.517241   \n",
       "4                          45.512821                          71.794872   \n",
       "\n",
       "   solvent_accessibility_exposed_80%  solvent_accessibility_exposed_100%  \n",
       "0                          80.405405                          100.000000  \n",
       "1                          83.181818                           99.090909  \n",
       "2                          86.206897                           99.507389  \n",
       "3                          86.699507                           99.507389  \n",
       "4                          89.102564                          100.000000  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv('./features.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npchi\\AppData\\Local\\Temp\\ipykernel_29064\\1046682262.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Label'].replace({'nAMP': 0, 'AMP': 1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Label'].replace({'nAMP': 0, 'AMP': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Label'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các tham số\n",
    "num_amino_acids = 20 \n",
    "max_length = 200     \n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWXY\"  \n",
    "dic_to_index = {val: i + 1 for i, val in enumerate(amino_acids)}  \n",
    "index_to_dic = {i + 1: val for i, val in enumerate(amino_acids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 16\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [dic_to_index[nuc] \u001b[38;5;28;01mfor\u001b[39;00m nuc \u001b[38;5;129;01min\u001b[39;00m sequence]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Example gene sequences\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#sequences = [\"ATGC\", \"GTCA\", \"GATTACA\"]\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#labels = [0, 0, 1]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Encode sequences\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m encoded_sequences \u001b[38;5;241m=\u001b[39m [\u001b[43mencode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#encoded_sequences\u001b[39;00m\n\u001b[0;32m     18\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m encoded_sequences])\n",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m, in \u001b[0;36mencode_sequence\u001b[1;34m(sequence)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_sequence\u001b[39m(sequence):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdic_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnuc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m nuc \u001b[38;5;129;01min\u001b[39;00m sequence]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'X'"
     ]
    }
   ],
   "source": [
    "sequences = df['Sequence'].values\n",
    "\n",
    "# Step 1: Encode the gene sequence into integers (e.g., 'A' -> 1, 'T' -> 2, 'G' -> 3, 'C' -> 4)\n",
    "# nucleotides = ['A', 'T', 'G', 'C']\n",
    "# nucleotide_dict = {nucleotide: idx + 1 for idx, nucleotide in enumerate(nucleotides)}\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    return [dic_to_index[nuc] for nuc in sequence]\n",
    "\n",
    "# Example gene sequences\n",
    "#sequences = [\"ATGC\", \"GTCA\", \"GATTACA\"]\n",
    "\n",
    "#labels = [0, 0, 1]\n",
    "\n",
    "# Encode sequences\n",
    "encoded_sequences = [encode_sequence(seq) for seq in sequences]\n",
    "#encoded_sequences\n",
    "max_length = max([len(seq) for seq in encoded_sequences])\n",
    "for i in range(len(encoded_sequences)):\n",
    "    if len(encoded_sequences[i]) < max_length:\n",
    "        encoded_sequences[i].extend([0] * (max_length - len(encoded_sequences[i])))\n",
    "X = np.array(encoded_sequences)\n",
    "#y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2222 - loss: 0.6938   \n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.6910 \n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6111 - loss: 0.6894 \n",
      "Epoch 4/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6111 - loss: 0.6880 \n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 0.6866 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Embedding for sequence ATGCAAA: [[0.49512506]]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define the model in TensorFlow\n",
    "# We will use an Embedding layer followed by an LSTM layer to learn sequence-level embeddings\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 8  # Dimensionality of the embedding vector\n",
    "lstm_units = 16    # Number of LSTM units\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    # Embedding Layer\n",
    "    tf.keras.layers.Embedding(input_dim = len(nucleotides) + 1, output_dim = embedding_dim, input_length = max_length),\n",
    "    \n",
    "    # LSTM Layer\n",
    "    tf.keras.layers.LSTM(lstm_units, return_sequences=False),  # return_sequences=False to output a single vector\n",
    "    \n",
    "    # Dense Layers for classification (optional, depends on your task)\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Example output layer (for classification)\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model (dummy labels for illustration purposes)\n",
    "# For this example, let's assume the sequences are labeled for a classification task (e.g., 0, 1, 2, 3)\n",
    "#labels = np.array([0, 1, 2])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=5, batch_size=2)\n",
    "\n",
    "# Step 5: Get the embeddings for a sequence\n",
    "sequence = \"ATGCAAA\"  # Example sequence\n",
    "encoded_sequence = encode_sequence(sequence)  # Encode the sequence\n",
    "encoded_sequence = np.expand_dims(encoded_sequence, axis=0)  # Add batch dimension\n",
    "\n",
    "# Get the embedding output\n",
    "embedding_output = model.predict(encoded_sequence)\n",
    "\n",
    "print(f\"Embedding for sequence {sequence}: {embedding_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01905316,  0.00744199, -0.01677316,  0.01889774,  0.05205274,\n",
       "         0.03196178, -0.00954081,  0.0293442 ],\n",
       "       [-0.01140689,  0.00232307,  0.02454604,  0.01072338,  0.04322114,\n",
       "        -0.04160134,  0.02519789, -0.0073183 ],\n",
       "       [-0.00293613, -0.03492306,  0.01700757,  0.01044878, -0.01957863,\n",
       "         0.01956827,  0.01042726, -0.05674615],\n",
       "       [-0.04168224,  0.03075428, -0.04115203,  0.00584471,  0.0204232 ,\n",
       "         0.00870383, -0.03223594,  0.00554315],\n",
       "       [ 0.04545868, -0.01904867,  0.01556143,  0.01035725, -0.01934252,\n",
       "         0.03147958,  0.03312983,  0.03830959]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = model.layers[0].get_weights()[0]\n",
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasstic search => \n",
    "#search "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tktmdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
